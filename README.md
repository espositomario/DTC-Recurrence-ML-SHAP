# Test mimmi

l
## mimmi branch
hahaha

## ire
mimmi tvb


pip install git+https://github.com/helias/shap.git@support-adaboost





https://link.springer.com/article/10.1007/s00405-023-08299-w#Sec2 #dataset paper
- UCI data n=383
- feature selection
- high scores
- hp tuning?

https://www.mdpi.com/2673-9585/4/4/29
- UCI data n=383
- SMOTE over-smpling
- HP tuning on test set?
- Very high scores 


https://arxiv.org/abs/2410.10907
- UCI data n=383
- DeepNN
- 80-20
- high scores
- LIME and Morris XAI
- no HP tuning

https://bmccancer.biomedcentral.com/articles/10.1186/s12885-024-12146-4
- china datset ~2000
- low scores
- different features
  

https://www.nature.com/articles/s41598-021-84504-2#Sec2
- other data ~1000
- low scores
- no HP tuning



https://www.mdpi.com/2079-9292/10/16/1973 #greed search



https://medium.com/@emilykmarsh/xgboost-feature-importance-233ee27c33a4 Why SHAP on XGBoost?


https://www.sciencedirect.com/science/article/abs/pii/S0957417421006540 Why nested Cv is overzealus

